{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyMCuP4DcuBGkqjRD+iVizbi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install -r requirements.txt --quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0jUUfJC-XkT0","executionInfo":{"status":"ok","timestamp":1705799862648,"user_tz":300,"elapsed":16125,"user":{"displayName":"Luqman Osman","userId":"18201663030053724993"}},"outputId":"371b3ccf-cf95-4697-fbba-fd7844c3e3b1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires fastapi, which is not installed.\n","lida 0.0.10 requires kaleido, which is not installed.\n","lida 0.0.10 requires python-multipart, which is not installed.\n","lida 0.0.10 requires uvicorn, which is not installed.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires openai, which is not installed.\n","llmx 0.0.15a0 requires tiktoken, which is not installed.\n","tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!git clone https://github.com/cg123/mergekit.git\n","!cd mergekit && pip install -qqq -e . --progress-bar off"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XFSgqbP_VtkR","executionInfo":{"status":"ok","timestamp":1705799880824,"user_tz":300,"elapsed":18181,"user":{"displayName":"Luqman Osman","userId":"18201663030053724993"}},"outputId":"9d45faa9-4b33-4d9b-813b-74f8a6fc7edd"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'mergekit'...\n","remote: Enumerating objects: 1114, done.\u001b[K\n","remote: Counting objects: 100% (394/394), done.\u001b[K\n","remote: Compressing objects: 100% (131/131), done.\u001b[K\n","remote: Total 1114 (delta 335), reused 269 (delta 263), pack-reused 720\u001b[K\n","Receiving objects: 100% (1114/1114), 272.89 KiB | 22.74 MiB/s, done.\n","Resolving deltas: 100% (783/783), done.\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building editable for mergekit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["MODEL_NAME = \"Frankenmerge_WizardLM\"\n","yaml_config = \"\"\"\n","\n","dtype: float16\n","merge_method: passthrough\n","slices:\n","- sources:\n","  - layer_range: [0, 20]\n","    model: WizardLM/WizardLM-70B-V1.0\n","- sources:\n","  - layer_range: [10, 30]\n","    model: WizardLM/WizardLM-70B-V1.0\n","- sources:\n","  - layer_range: [20, 40]\n","    model: WizardLM/WizardLM-70B-V1.0\n","- sources:\n","  - layer_range: [30, 50]\n","    model: WizardLM/WizardLM-70B-V1.0\n","- sources:\n","  - layer_range: [40, 60]\n","    model: WizardLM/WizardLM-70B-V1.0\n","- sources:\n","  - layer_range: [50, 70]\n","    model: WizardLM/WizardLM-70B-V1.0\n","- sources:\n","  - layer_range: [60, 80]\n","    model: WizardLM/WizardLM-70B-V1.0\n","\"\"\""],"metadata":{"id":"0mEtYjWqTNGT","executionInfo":{"status":"ok","timestamp":1705799880824,"user_tz":300,"elapsed":3,"user":{"displayName":"Luqman Osman","userId":"18201663030053724993"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Save config as yaml file\n","with open('config.yaml', 'w', encoding=\"utf-8\") as f:\n","    f.write(yaml_config)"],"metadata":{"id":"lj9JfnE0VqxG","executionInfo":{"status":"ok","timestamp":1705799881208,"user_tz":300,"elapsed":387,"user":{"displayName":"Luqman Osman","userId":"18201663030053724993"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Merge models\n","!mergekit-yaml config.yaml merge --copy-tokenizer --allow-crimes --out-shard-size 1B --lazy-unpickle"],"metadata":{"id":"ayQXyhYKV8Ys"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -qU huggingface_hub\n","\n","from huggingface_hub import ModelCard, ModelCardData\n","from jinja2 import Template\n","\n","username = \"luqmanxyz\"\n","\n","template_text = \"\"\"\n","---\n","license: apache-2.0\n","tags:\n","- merge\n","- mergekit\n","{%- for model in models %}\n","- {{ model }}\n","{%- endfor %}\n","---\n","\n","# {{ model_name }}\n","\n","{{ model_name }} is a merge of the following models using [mergekit](https://github.com/cg123/mergekit):\n","\n","{%- for model in models %}\n","* [{{ model }}](https://huggingface.co/{{ model }})\n","{%- endfor %}\n","\n","## 🧩 Configuration\n","\n","```yaml\n","{{- yaml_config -}}\n","```\n","\"\"\"\n","\n","# Create a Jinja template object\n","jinja_template = Template(template_text.strip())\n","\n","# Get list of models from config\n","data = yaml.safe_load(yaml_config)\n","if \"models\" in data:\n","    models = [data[\"models\"][i][\"model\"] for i in range(len(data[\"models\"])) if \"parameters\" in data[\"models\"][i]]\n","elif \"parameters\" in data:\n","    models = [data[\"slices\"][0][\"sources\"][i][\"model\"] for i in range(len(data[\"slices\"][0][\"sources\"]))]\n","elif \"slices\" in data:\n","    models = [data[\"slices\"][i][\"sources\"][0][\"model\"] for i in range(len(data[\"slices\"]))]\n","else:\n","    raise Exception(\"No models or slices found in yaml config\")\n","\n","# Fill the template\n","content = jinja_template.render(\n","    model_name=MODEL_NAME,\n","    models=models,\n","    yaml_config=yaml_config,\n","    username=username,\n",")\n","\n","# Save the model card\n","card = ModelCard(content)\n","card.save('merge/README.md')"],"metadata":{"id":"3FP6nuznWGjQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import userdata\n","from huggingface_hub import HfApi\n","\n","username = \"luqmanxyz\"\n","\n","# Defined in the secrets tab in Google Colab\n","api = HfApi(token=userdata.get(\"hf\"))\n","\n","api.create_repo(\n","    repo_id=f\"{username}/{MODEL_NAME}\",\n","    repo_type=\"model\"\n",")\n","api.upload_folder(\n","    repo_id=f\"{username}/{MODEL_NAME}\",\n","    folder_path=\"merge\",\n",")"],"metadata":{"id":"_qnaQOqTdAl5"},"execution_count":null,"outputs":[]}]}